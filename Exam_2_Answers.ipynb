{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Computional Biology. Exam_2_Answers\n",
    "\n",
    "Student: Álvaro García López"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1:\n",
    "\n",
    "We use the csv library to handle the files \"Germplasm.tsv\" and \"LocusGene.tsv\". Then, we can open these file (as \"locusgene\" and germplasm\") using the function \"open\" in \"read\" mode (it is by default) because we are not going to add more data to the files (we just want to access the current data). After open them, we create a new dictionary of each file (\"locusgene_dict\" and \"germplasm_dict\", respectively) using the \"csv.DictReader\" function (since are .tsv files, we set the delimiter as a tab \"\\t\".\n",
    "\n",
    "Next, we create a variable called \"no_coincidences\" for counting the number of lines of data that do not have the same information (being in the same line position). At the beggining, we set this variable as 0.\n",
    "\n",
    "Now we create the actual loops that are going to answer our original question using \"for\". We create a first loop (using dictionary \"locusgene_dict\") and, after that, we nested another loop into the first one (using dictionary \"germplasm_dict\").\n",
    "\n",
    "When you nested a loop into another one, for an iteration of the first loop, the nested loop is completed run, but this is not what we want, we want to come back to the first loop in each iteration. So we are going to use \"break\" at the end of the nested loop. This way, only one iteration in the nested loop is run for each iteration of the first loop. In other words, we run once the first loop, once the nested loop and then come back to the first loop's next iteration.\n",
    "\n",
    "So, this way, we can compare the \"Locus\" in the files one by one and in order. To make it clear, we ask Python to print this couples of \"Locus\" one by one and rqrite bellow them if they are the same or not. Every time that the answers is not, we add +1 to the variable \"no_coincidences\". Finally, we expose the final result. If the \"no_coincidences\" variable still equal to zero after all the loop iterations, we print \"All the lines of data are in the same sequence (order) in both files\" and if, on the contrary, it is not equal to zero we expuse the number of lines that are not equal (using .format and the variable \"no_coincidences\").\n",
    "\n",
    "We close the files by the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #Firstly, we import csv library to use its functions.\n",
    "\n",
    "#We open the files and create dictionaries of them.\n",
    "locusgene = open (\"LocusGene.tsv\")\n",
    "germplasm = open (\"Germplasm.tsv\") \n",
    "locusgene_dict = csv.DictReader(locusgene, delimiter='\\t', quotechar='\"')\n",
    "germplasm_dict = csv.DictReader(germplasm, delimiter='\\t', quotechar='\"')\n",
    "\n",
    "no_coincidences = 0 #We set this variable as 0 at the beggining.\n",
    "for row1 in locusgene_dict:\n",
    "    for row2 in germplasm_dict:\n",
    "        print(row1[\"Locus\"])\n",
    "        print(row2[\"Locus\"])\n",
    "        if row1 [\"Locus\"] == row2[\"Locus\"]:\n",
    "            print(\"Both AGI are the same\")\n",
    "        else:\n",
    "            print(\"Both AGI are not the same\")\n",
    "            no_coincidences += 1\n",
    "        break\n",
    "print(\"\\nFinal Result:\\n\")  \n",
    "if no_coincidences == 0:\n",
    "    print(\"\"\"All the lines of data are in the\n",
    "same sequence (order) in both files\"\"\") #To make it clear, we consider that \"same sequence\" or \"same order\" is the same in this case. \n",
    "else:\n",
    "    print(\"{} lines of data are not the same in both files\".format(no_coincidences)) \n",
    "    #If \"no_coincidences\" is not equal to zero we can also now how many lines are not equal between the files \n",
    "    #asking for the \"no_coincidences\" final value.\n",
    "\n",
    "locusgene.close()\n",
    "germplasm.close() #We close the files by the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2:\n",
    "\n",
    "First of all, we check that the mysql docker is working properly and we connect to it from Jupyter (Python) using:\n",
    "%load_ext sql\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql\n",
    "\n",
    "After that, we create a database called \"database_exam2\" and we use it to create tables inside it.\n",
    "We create two tables: \n",
    "-The first one is called \"germplasm\" and we use the \"locus\" column as the primary key (because it is in both document and in the same order).  Its data type is varchar. And we as aditional columns \"germplasm\" (VARCHAR), \"phenotype\" (VARCHAR) and pubmed (INTEGER). All columns are NOT NULL, so they all have to contain information in all their entries.\n",
    "-The second table is called \"locusgene\". We use again \"locus\" column as the primary key (VARCHAR) and we add the columns: \"gene\" (VARCHAR), \"protein_length\" (INTEGER). Again we set all columns as NOT NULL.\n",
    "\n",
    "Creating both table, we have careful with the VARCHAR lengths, make it enough big to fix the expected (an maybe some unexpected) entries.\n",
    "\n",
    "Finally, we know that both tables are link in 1:1 relationship, because they have the same \"locus\" as the primary key. And we know, due to the previous problem, that this \"locus\" are exactly the same (number of them and its order) in the files that we are going to use later to fill the database. In other worlds, all entries in each table are going to have an entry in the other table with the same \"locus\" (primary key) and in the same position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: root@mysql'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql #we connect to mysql docker from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "(pymysql.err.ProgrammingError) (1007, \"Can't create database 'proff'; database exists\")\n",
      "[SQL: create database proff;]\n",
      "(Background on this error at: http://sqlalche.me/e/f405)\n",
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "0 rows affected.\n",
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Database</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>information_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>database_exam2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>mysql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>performance_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>sys</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('information_schema',),\n",
       " ('database_exam2',),\n",
       " ('mysql',),\n",
       " ('performance_schema',),\n",
       " ('sys',)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql create database database_exam2; #creating the database\n",
    "%sql show databases; #checking that it has been created OK.\n",
    "%sql use database_exam2; #using it (to be able to create tables inside it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "0 rows affected.\n",
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Field</th>\n",
       "        <th>Type</th>\n",
       "        <th>Null</th>\n",
       "        <th>Key</th>\n",
       "        <th>Default</th>\n",
       "        <th>Extra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>locus</td>\n",
       "        <td>varchar(20)</td>\n",
       "        <td>NO</td>\n",
       "        <td>PRI</td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>germplasm</td>\n",
       "        <td>varchar(30)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>phenotype</td>\n",
       "        <td>varchar(5000)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>pubmed</td>\n",
       "        <td>int(11)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('locus', 'varchar(20)', 'NO', 'PRI', None, ''),\n",
       " ('germplasm', 'varchar(30)', 'NO', '', None, ''),\n",
       " ('phenotype', 'varchar(5000)', 'NO', '', None, ''),\n",
       " ('pubmed', 'int(11)', 'NO', '', None, '')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql CREATE TABLE germplasm(locus VARCHAR(20) NOT NULL PRIMARY KEY, germplasm VARCHAR(30) NOT NULL, phenotype VARCHAR(5000) NOT NULL, pubmed INTEGER NOT NULL);\n",
    "%sql DESCRIBE germplasm #checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Field</th>\n",
       "        <th>Type</th>\n",
       "        <th>Null</th>\n",
       "        <th>Key</th>\n",
       "        <th>Default</th>\n",
       "        <th>Extra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>locus</td>\n",
       "        <td>varchar(20)</td>\n",
       "        <td>NO</td>\n",
       "        <td>PRI</td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>gene</td>\n",
       "        <td>varchar(20)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>protein_length</td>\n",
       "        <td>int(11)</td>\n",
       "        <td>NO</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('locus', 'varchar(20)', 'NO', 'PRI', None, ''),\n",
       " ('gene', 'varchar(20)', 'NO', '', None, ''),\n",
       " ('protein_length', 'int(11)', 'NO', '', None, '')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql CREATE TABLE locusgene(locus VARCHAR(20) NOT NULL PRIMARY KEY, gene VARCHAR(20) NOT NULL, protein_length INTEGER NOT NULL);\n",
    "%sql DESCRIBE locusgene #checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Tables_in_database_exam2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>germplasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>locusgene</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('germplasm',), ('locusgene',)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql show tables; #just to check that all went right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "First, in order to access to the mysql databases from Python we import the library \"pymysql.cursors\".\n",
    "\n",
    "Next, we open again the \"LocusGene.tsv\" and \"Germplasm.tsv\" and define again its respectives dictionaries (we did in the problem 1, but we do it again just to make sure). And we establish the connection to the \"database_exam2\" (that we created in the previous problem). \n",
    "\n",
    "We use the try function (this allow us to do it in a safer way). We use two new loop to insert the data, that work essentially in the same way. \n",
    "\n",
    "We have two dictionaries that have its keys and its values. Focusing on only one (to make it clearer), the values in this case are lists, in these lists we have the data that we are going to use to fill database's table. So, we insert into the table the data from the lists of the dictionary as \"VALUES\".  We are able to insert the data of the lists in the original order due to the loop. And using some {} and .format followed by the dictionaries' keys we can assign which list (of the dictionary) is going to correspond to each column of the table.\n",
    "\n",
    "In other words, we insert the data of lists of the dictionaries into the database in its original order and we assign to each table's column the key which list we want to introduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pymysql.cursors #importing the library that we need\n",
    "\n",
    "locusgene = open (\"LocusGene.tsv\")\n",
    "germplasm = open (\"Germplasm.tsv\") \n",
    "locusgene_dict = csv.DictReader(locusgene, delimiter='\\t', quotechar='\"')\n",
    "germplasm_dict = csv.DictReader(germplasm, delimiter='\\t', quotechar='\"')\n",
    "\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='database_exam2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor) #connecting to the database \n",
    "\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        for row in germplasm_dict:\n",
    "            sql = \"INSERT INTO germplasm (locus, germplasm, phenotype, pubmed) VALUES ('{}', '{}', '{}', {});\".format(row[\"Locus\"], row[\"germplasm\"], row[\"phenotype\"], row[\"pubmed\"])\n",
    "            cursor.execute(sql)\n",
    "        for row in locusgene_dict:\n",
    "            sql = \"INSERT INTO locusgene (locus, gene, protein_length) VALUES ('{}', '{}', {});\".format(row[\"Locus\"], row[\"Gene\"], row[\"ProteinLength\"])\n",
    "            cursor.execute(sql)\n",
    "    connection.commit()\n",
    "\n",
    "finally:\n",
    "    print (\"Done!\") #just to be able of establish a \"finally\" to the \"try\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sql SELECT * FROM germplasm \n",
    "#%sql SELECT * FROM locusgene\n",
    "#we use this to check that the databases was filled with the desired files correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Report Number 1:\n",
    "\n",
    "To achieve the first point of the problem we use the JOIN clause to have the content of bpth database's tables in the same table and the entries with the same \"Locus\" in the same row (and in the original order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the full outer clause to achieve this\n",
    "%sql SELECT * FROM germplasm JOIN locusgene ON \\\n",
    "germplasm.locus = locusgene.locus;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report Number 2:\n",
    "We use a JOIN clause again as the same way as the previous report. But we ask only for the row in which the column \"gene\" has the genes \"SKOR\" or \"MAA3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM germplasm JOIN locusgene ON \\\n",
    "germplasm.locus = locusgene.locus WHERE \\\n",
    "locusgene.gene = 'SKOR' OR \\\n",
    "locusgene.gene = 'MAA3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report Number 3:\n",
    "This report is not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@127.0.0.1:3306/mysql\n",
      "32 rows affected.\n",
      "+-----------+\n",
      "|   locus   |\n",
      "+-----------+\n",
      "| AT1G01040 |\n",
      "| AT1G01060 |\n",
      "| AT1G01140 |\n",
      "| AT1G01220 |\n",
      "| AT2G03720 |\n",
      "| AT2G03800 |\n",
      "| AT2G04240 |\n",
      "| AT2G05210 |\n",
      "| AT3G02130 |\n",
      "| AT3G02140 |\n",
      "| AT3G02230 |\n",
      "| AT3G02260 |\n",
      "| AT3G02310 |\n",
      "| AT3G02680 |\n",
      "| AT3G02850 |\n",
      "| AT3G02870 |\n",
      "| AT3G03260 |\n",
      "| AT4G14790 |\n",
      "| AT4G15210 |\n",
      "| AT4G15560 |\n",
      "| AT4G15570 |\n",
      "| AT4G15802 |\n",
      "| AT4G15880 |\n",
      "| AT4G16420 |\n",
      "| AT4G16480 |\n",
      "| AT5G10480 |\n",
      "| AT5G10510 |\n",
      "| AT5G11110 |\n",
      "| AT5G11260 |\n",
      "| AT5G11510 |\n",
      "| AT5G12200 |\n",
      "| AT5G13290 |\n",
      "+-----------+\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-5b2b78bdfb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mAGI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sql'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SELECT germplasm.locus FROM germplasm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAGI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmatchObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'AT1G.+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAGI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatchObj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/lib/python3.7/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    182\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#This report is not finished\n",
    "import re \n",
    "AGI = %sql SELECT germplasm.locus FROM germplasm\n",
    "print (AGI)\n",
    "matchObj = re.search(r'AT1G.+', AGI)  \n",
    "\n",
    "if matchObj:\n",
    "   print (\"match.group(0)\")\n",
    "   \n",
    "else:\n",
    "   print (\"No match\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
